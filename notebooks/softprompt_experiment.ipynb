{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2e091b4",
   "metadata": {},
   "source": [
    "# Soft-Prompt Experiment Notebook\n",
    "\n",
    "This notebook orchestrates hyperparameter experiments for **Brand Voice Rewriter**.\n",
    "\n",
    "**What it does:**  \n",
    "- Runs `scripts/train_gemma_softprompt.py` multiple times with different hyperparameters.  \n",
    "- Logs and aggregates metrics from `artifacts/runs/<style>/run_*.json`.  \n",
    "- Picks the best configurations by validation proxies (time/seconds, etc.) and your custom metrics.  \n",
    "- Optionally renders visualization figures using `scripts/visualize_softprompt.py`.\n",
    "\n",
    "> **Run this notebook from the project root** (same level as `scripts/` and `config/`).  \n",
    "> Requires a GPU machine for training; CPU is fine for data aggregation/plots.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c9b564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, time, subprocess, shlex\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import yaml\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "os.chdir(PROJECT_ROOT)\n",
    "\n",
    "CONFIG_PATH = PROJECT_ROOT / \"config\" / \"app.yaml\"\n",
    "RUNS_ROOT   = PROJECT_ROOT / \"artifacts\" / \"softprompt\"\n",
    "FIG_ROOT = PROJECT_ROOT / \"artifacts\" / \"reports\" / \"figures\"\n",
    "FIG_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TEST_CSV    = PROJECT_ROOT / \"data\" / \"datasets\" / \"neutral_texts.csv\"\n",
    "SOFTP_ROOT  = None\n",
    "\n",
    "cfg = yaml.safe_load(open(CONFIG_PATH, \"r\", encoding=\"utf-8\"))\n",
    "BASE_MODEL_ID = cfg[\"model_id\"]\n",
    "\n",
    "STYLES = [\"fintech\", \"compliance\", \"motivation_guru\", \"ai_newsletter\"]\n",
    "\n",
    "print(\"Working dir:\", PROJECT_ROOT)\n",
    "print(\"Config:\", CONFIG_PATH)\n",
    "print(\"Runs root:\", RUNS_ROOT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168ef774",
   "metadata": {},
   "source": [
    "## Choose style and search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013cad1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll compute grad_accum to hit eff_batch ~ 32.\n",
    "PER_DEVICE_BSZ = 4           # set 2 on 16GB T4, 4 on 24GB L4/A10\n",
    "EFF_BATCH      = 4\n",
    "GRAD_ACCUM     = max(1, EFF_BATCH // PER_DEVICE_BSZ)\n",
    "\n",
    "# === Search grid (coarse) ===\n",
    "V_CHOICES   = [8]\n",
    "SEQ_CHOICES = [64]\n",
    "LR_CHOICES  = [1e-3]\n",
    "EPOCHS      = [5]\n",
    "\n",
    "# Initialization prompt variants (short style hints)\n",
    "INIT_PROMPTS = {\n",
    "    \"TEXT_neutral\": \"[rewrite]\"\n",
    "}\n",
    "INIT_KEYS = list(INIT_PROMPTS.keys())\n",
    "\n",
    "print(\"grad_accum:\", GRAD_ACCUM, \"(per_device_bsz:\", PER_DEVICE_BSZ, \")\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2e376f",
   "metadata": {},
   "source": [
    "## Run a single training trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068e1052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trial(style:str, vtok:int, seq_len:int, lr:float, epochs:int, bsz:int, grad_accum:int, init_key:str):\n",
    "    \"\"\"Launch a single training run via CLI. Returns (ok, stdout, stderr).\"\"\"\n",
    "    # We pass extra env to override init_text inside your trainer (if supported).\n",
    "    env = os.environ.copy()\n",
    "    env[\"PYTHONPATH\"] = str(PROJECT_ROOT)\n",
    "    env[\"BVW_INIT_TEXT_VARIANT\"] = init_key  # your trainer can read this to choose init\n",
    "\n",
    "    cmd = f\"python scripts/train_gemma_softprompt.py --style {style} --virtual-tokens {vtok} --max-seq-len {seq_len} --lr {lr} --epochs {epochs} --bsz {bsz}\"\n",
    "\n",
    "    # If your trainer supports grad_accum and checkpointing flags, add them here:\n",
    "    # cmd += f\" --grad-accum {grad_accum} --ckpt\"\n",
    "\n",
    "    print(\"\\n[RUN]\", cmd)\n",
    "    start = time.time()\n",
    "    proc = subprocess.run(shlex.split(cmd), cwd=PROJECT_ROOT, capture_output=True, text=True, env=env)\n",
    "    dur = time.time() - start\n",
    "    ok = proc.returncode == 0\n",
    "    print(proc.stdout)\n",
    "    if not ok:\n",
    "        print(\"[ERR]\", proc.stderr)\n",
    "    return ok, proc.stdout, proc.stderr, dur\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a514bab",
   "metadata": {},
   "source": [
    "## Launch coarse grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce04ab0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for v in V_CHOICES:\n",
    "    for seql in SEQ_CHOICES:\n",
    "        for lrate in LR_CHOICES:\n",
    "            for init_key in INIT_KEYS:\n",
    "                for STYLE in STYLES:\n",
    "                \n",
    "                    ok, out, err, dur = run_trial(\n",
    "                        style=STYLE, vtok=v, seq_len=seql, lr=lrate, epochs=EPOCHS[0],\n",
    "                        bsz=PER_DEVICE_BSZ, grad_accum=GRAD_ACCUM, init_key=init_key\n",
    "                    )\n",
    "                    results.append({\n",
    "                        \"style\": STYLE, \"vtok\": v, \"seq_len\": seql, \"lr\": lrate, \"epochs\": EPOCHS[0],\n",
    "                        \"per_device_bsz\": PER_DEVICE_BSZ, \"grad_accum\": GRAD_ACCUM, \"duration_sec\": round(dur,2),\n",
    "                        \"ok\": ok\n",
    "                    })\n",
    "\n",
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98214488",
   "metadata": {},
   "source": [
    "## Collect metrics from artifacts/runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1110401",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base = pd.read_csv(TEST_CSV)\n",
    "df_base.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d395fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_run_dir(style: str) -> Path:\n",
    "    style_root = RUNS_ROOT / style\n",
    "    if not style_root.exists():\n",
    "        raise RuntimeError(f\"No softprompt dir for style '{style}' at {style_root}\")\n",
    "    runs = sorted([d for d in style_root.iterdir() if d.is_dir() and d.name.startswith(\"run_\")])\n",
    "    if not runs:\n",
    "        raise RuntimeError(f\"No run_* dirs for style '{style}' at {style_root}\")\n",
    "    return runs[-1]\n",
    "\n",
    "\n",
    "def load_base_model_and_tokenizer(device: str = \"cpu\"):\n",
    "    tok = AutoTokenizer.from_pretrained(BASE_MODEL_ID, trust_remote_code=True, use_fast=True)\n",
    "    dtype = torch.float16 if device == \"cuda\" else torch.float32\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        BASE_MODEL_ID,\n",
    "        trust_remote_code=True,\n",
    "        low_cpu_mem_usage=True,\n",
    "        dtype=dtype,\n",
    "    ).to(device)\n",
    "    model.eval()\n",
    "    return tok, model\n",
    "\n",
    "\n",
    "def load_style_model(style: str, base_model, device: str = \"cpu\"):\n",
    "    run_dir = get_latest_run_dir(style)\n",
    "    print(f\"[LOAD] style={style} run={run_dir.name}\")\n",
    "    peft_model = PeftModel.from_pretrained(base_model, run_dir)\n",
    "    peft_model.to(device)\n",
    "    peft_model.eval()\n",
    "    return peft_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f5c336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite_with_style(\n",
    "    tok,\n",
    "    styled_model,\n",
    "    device: str,\n",
    "    text: str,\n",
    "    style: str,\n",
    "    max_new_tokens: int = 160,\n",
    "    temperature: float = 0.0,\n",
    "    top_p: float = 0.9\n",
    ") -> str:\n",
    "    \n",
    "    system_prompt = (\n",
    "        f\"You are a brand voice rewriter. \"\n",
    "        f\"Rewrite the text into the '{style}' brand voice. \"\n",
    "        f\"Preserve meaning and approximate length. \"\n",
    "        f\"Your output MUST follow this EXACT format:\\n\"\n",
    "        f\"[rewrite]\\n\"\n",
    "        f\"<rewritten text here>\\n\"\n",
    "        f\"[/rewrite]\\n\"\n",
    "        f\"No explanations. No alternatives. No extra words. \"\n",
    "        f\"DO NOT output anything outside the [rewrite] block.\"\n",
    "    )\n",
    "\n",
    "    prompt = (\n",
    "        f\"{system_prompt}\\n\\n\"\n",
    "        f\"Original text:\\n{text.strip()}\\n\\n\"\n",
    "        f\"Rewritten text:\\n\"\n",
    "        f\"[rewrite]\\n\"\n",
    "    )\n",
    "\n",
    "    # Tokenize\n",
    "    inputs = tok(prompt, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    # Generate\n",
    "    with torch.no_grad():\n",
    "        out = styled_model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=False,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            eos_token_id=tok.eos_token_id,\n",
    "        )\n",
    "\n",
    "    generated_ids = out[0]\n",
    "\n",
    "    # Extract only generated continuation\n",
    "    prompt_len = inputs[\"input_ids\"].shape[1]\n",
    "    gen_ids = generated_ids[prompt_len:]\n",
    "    decoded = tok.decode(gen_ids, skip_special_tokens=True)\n",
    "\n",
    "    # Normalize whitespace\n",
    "    decoded = decoded.strip()\n",
    "\n",
    "    # Extract content between tags\n",
    "    if \"[rewrite]\" in decoded:\n",
    "        decoded = decoded.split(\"[rewrite]\", 1)[-1]\n",
    "    if \"[/rewrite]\" in decoded:\n",
    "        decoded = decoded.split(\"[/rewrite]\", 1)[0]\n",
    "\n",
    "    final_text = decoded.strip()\n",
    "\n",
    "    return final_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be40506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite_neutral(tok, base_model, device: str, text: str,\n",
    "                    max_new_tokens: int = 160, temperature: float = 0.0, top_p: float = 0.9) -> str:\n",
    "    system_prompt = (\n",
    "        f\"You are a brand voice rewriter. \"\n",
    "        f\"Rewrite the text in neutral tone. \"\n",
    "        f\"Preserve meaning and approximate length. \"\n",
    "        f\"Your output MUST follow this EXACT format:\\n\"\n",
    "        f\"[rewrite]\\n\"\n",
    "        f\"<rewritten text here>\\n\"\n",
    "        f\"[/rewrite]\\n\"\n",
    "        f\"No explanations. No alternatives. No extra words. \"\n",
    "        f\"DO NOT output anything outside the [rewrite] block.\"\n",
    "    )\n",
    "    #system_prompt = (f\"Rewrite the input in the user's voice while preserving meaning.\")\n",
    "    prompt = (\n",
    "            f\"{system_prompt}\\n\\n\"\n",
    "            \"Original text:\\n\"\n",
    "            f\"{text.strip()}\\n\\n\"\n",
    "            \"Rewritten text:\\n\"\n",
    "        )\n",
    "\n",
    "    inputs = tok(prompt, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = base_model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=False,             \n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            eos_token_id=tok.eos_token_id,\n",
    "        )\n",
    "\n",
    "    generated_ids = out[0]\n",
    "\n",
    "    # Extract only generated continuation\n",
    "    prompt_len = inputs[\"input_ids\"].shape[1]\n",
    "    gen_ids = generated_ids[prompt_len:]\n",
    "    decoded = tok.decode(gen_ids, skip_special_tokens=True)\n",
    "\n",
    "    # Normalize whitespace\n",
    "    decoded = decoded.strip()\n",
    "\n",
    "    # Extract content between tags\n",
    "    if \"[rewrite]\" in decoded:\n",
    "        decoded = decoded.split(\"[rewrite]\", 1)[-1]\n",
    "    if \"[/rewrite]\" in decoded:\n",
    "        decoded = decoded.split(\"[/rewrite]\", 1)[0]\n",
    "\n",
    "    final_text = decoded.strip()\n",
    "    \n",
    "    return final_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c094ed96",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "tok, base_model = load_base_model_and_tokenizer(device=device)\n",
    "\n",
    "base_rewrites = []\n",
    "for _, row in df_base.iterrows():\n",
    "    txt = row[\"text\"]\n",
    "    out = rewrite_neutral(tok, base_model, device, txt)\n",
    "    base_rewrites.append(out)\n",
    "\n",
    "df_base[\"neutral_out\"] = base_rewrites\n",
    "\n",
    "rows = []\n",
    "for style in STYLES:\n",
    "    styled_model = load_style_model(style, base_model, device=device)\n",
    "    for _, row in df_base.iterrows():\n",
    "        sample_id = row[\"id\"]\n",
    "        src = row[\"text\"]\n",
    "        neutral = row[\"neutral_out\"]\n",
    "        styled = rewrite_with_style(tok, styled_model, device, src, style)\n",
    "        rows.append({\n",
    "            \"id\": sample_id,\n",
    "            \"style\": style,\n",
    "            \"src\": src,\n",
    "            \"neutral_out\": neutral,\n",
    "            \"styled_out\": styled,\n",
    "        })\n",
    "\n",
    "df_styles = pd.DataFrame(rows)\n",
    "\n",
    "df_styles.to_csv('test_results_brak.csv')\n",
    "df_base.to_csv('test_results_neutral_brak.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed45ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U sentence-transformers\n",
    "\n",
    "emb_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "def cosine_angle(v1: np.ndarray, v2: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    v1 = v1 / (np.linalg.norm(v1) + 1e-8)\n",
    "    v2 = v2 / (np.linalg.norm(v2) + 1e-8)\n",
    "    cos_sim = float(np.clip(np.dot(v1, v2), -1.0, 1.0))\n",
    "    angle = math.degrees(math.acos(cos_sim))\n",
    "    return angle, cos_sim\n",
    "\n",
    "angles_rows = []\n",
    "\n",
    "for (style, sample_id), grp in df_styles.groupby([\"style\", \"id\"]):\n",
    "    neutral_text = grp.iloc[0][\"neutral_out\"]\n",
    "    styled_text = grp.iloc[0][\"styled_out\"]\n",
    "\n",
    "    emb_neutral = emb_model.encode(neutral_text, convert_to_numpy=True)\n",
    "    emb_styled  = emb_model.encode(styled_text, convert_to_numpy=True)\n",
    "\n",
    "    angle_deg, cos_sim = cosine_angle(emb_neutral, emb_styled)\n",
    "\n",
    "    angles_rows.append({\n",
    "        \"id\": sample_id,\n",
    "        \"style\": style,\n",
    "        \"angle_deg\": angle_deg,\n",
    "        \"cosine\": cos_sim,\n",
    "        \"embedding\": emb_styled,\n",
    "    })\n",
    "\n",
    "df_angles = pd.DataFrame(angles_rows)\n",
    "df_angles.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95b773e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "df_angles.boxplot(column=\"angle_deg\", by=\"style\")\n",
    "plt.title(\"Angle between neutral and styled outputs (degrees)\")\n",
    "plt.suptitle(\"\")\n",
    "plt.ylabel(\"Angle (deg)\")\n",
    "plt.xlabel(\"Style\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb78f31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = df_angles.pivot(index=\"id\", columns=\"style\", values=\"angle_deg\").sort_index()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.imshow(pivot.values, aspect=\"auto\")\n",
    "plt.colorbar(label=\"Angle (deg)\")\n",
    "plt.xticks(ticks=np.arange(len(pivot.columns)), labels=pivot.columns, rotation=45, ha=\"right\")\n",
    "plt.yticks(ticks=np.arange(len(pivot.index)), labels=pivot.index)\n",
    "plt.title(\"Angle heatmap: neutral vs styled per sample/style\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbc6521",
   "metadata": {},
   "outputs": [],
   "source": [
    "STYLES = [\"fintech\", \"compliance\", \"motivation_guru\", \"ai_newsletter\"]\n",
    "\n",
    "length_map = df_base.set_index(\"id\")[\"neutral_out\"].apply(lambda s: len(s.split()))\n",
    "df_angles[\"neutral_len\"] = df_angles[\"id\"].map(length_map)\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "for style in STYLES:\n",
    "    sub = df_angles[df_angles[\"style\"] == style]\n",
    "    plt.scatter(sub[\"neutral_len\"], sub[\"angle_deg\"], label=style, alpha=0.7)\n",
    "\n",
    "plt.xlabel(\"Neutral output length (words)\")\n",
    "plt.ylabel(\"Angle (deg)\")\n",
    "plt.title(\"Angle vs neutral text length\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3b8182",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"neutral_out\" not in df_base.columns:\n",
    "    if \"output\" in df_base.columns:\n",
    "        df_base = df_base.rename(columns={\"output\": \"neutral_out\"})\n",
    "    elif \"text\" in df_base.columns:\n",
    "        df_base = df_base.rename(columns={\"text\": \"neutral_out\"})\n",
    "    else:\n",
    "        raise RuntimeError(\"Cannot find neutral text column in df_base\")\n",
    "\n",
    "if \"styled_out\" not in df_styles.columns:\n",
    "    if \"output\" in df_styles.columns:\n",
    "        df_styles = df_styles.rename(columns={\"output\": \"styled_out\"})\n",
    "    elif \"text\" in df_styles.columns:\n",
    "        df_styles = df_styles.rename(columns={\"text\": \"styled_out\"})\n",
    "    else:\n",
    "        raise RuntimeError(\"Cannot find styled text column in df_styles\")\n",
    "\n",
    "df_base[\"neutral_out\"]  = df_base[\"neutral_out\"].fillna(\"\").astype(str)\n",
    "df_styles[\"styled_out\"] = df_styles[\"styled_out\"].fillna(\"\").astype(str)\n",
    "df_styles[\"style\"]      = df_styles[\"style\"].astype(str)\n",
    "\n",
    "def cosine_angle(v1: np.ndarray, v2: np.ndarray):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    v1 = v1 / (np.linalg.norm(v1) + 1e-8)\n",
    "    v2 = v2 / (np.linalg.norm(v2) + 1e-8)\n",
    "    cos_sim = float(np.clip(np.dot(v1, v2), -1.0, 1.0))\n",
    "    angle = math.degrees(math.acos(cos_sim))\n",
    "    return angle, cos_sim\n",
    "\n",
    "centroids = {}\n",
    "\n",
    "neutral_texts = df_base[\"neutral_out\"].tolist()\n",
    "neutral_embs  = emb_model.encode(neutral_texts, convert_to_numpy=True)\n",
    "centroids[\"neutral\"] = neutral_embs.mean(axis=0)\n",
    "\n",
    "styles = sorted(df_styles[\"style\"].unique().tolist())\n",
    "\n",
    "for style in styles:\n",
    "    sub = df_styles[df_styles[\"style\"] == style]\n",
    "    texts = sub[\"styled_out\"].tolist()\n",
    "    texts = [t for t in texts if isinstance(t, str) and t.strip()]\n",
    "    if not texts:\n",
    "        continue\n",
    "    embs = emb_model.encode(texts, convert_to_numpy=True)\n",
    "    centroids[style] = embs.mean(axis=0)\n",
    "\n",
    "\n",
    "labels = [\"neutral\"] + styles \n",
    "n = len(labels)\n",
    "\n",
    "angle_matrix = np.zeros((n, n), dtype=float)\n",
    "\n",
    "for i, s1 in enumerate(labels):\n",
    "    for j, s2 in enumerate(labels):\n",
    "        v1 = centroids[s1]\n",
    "        v2 = centroids[s2]\n",
    "        angle_deg, _ = cosine_angle(v1, v2)\n",
    "        angle_matrix[i, j] = angle_deg\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "im = plt.imshow(angle_matrix, aspect=\"equal\")\n",
    "\n",
    "plt.colorbar(im, label=\"Angle between style centroids (degrees)\")\n",
    "plt.xticks(ticks=np.arange(n), labels=labels, rotation=45, ha=\"right\")\n",
    "plt.yticks(ticks=np.arange(n), labels=labels)\n",
    "plt.title(\"Style vs Style: angular distance (neutral + styled)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc2032a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
